{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7be-4wZ8zuO"
      },
      "source": [
        "# I. Import the dataset. Define x and y.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "id": "IEomVUgHqQ5F"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "#Pandas is a powerful open-source data analysis and manipulation library for Python.\n",
        "#It provides data structures and functions for efficiently working with structured data, such as tables and time series data.\n",
        "\n",
        "dataset = pd.read_csv('chem-date.csv')\n",
        "\n",
        "#In google colab, we run files cell by cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0Z529zPcqyRW"
      },
      "outputs": [],
      "source": [
        "#We'll set up x and y attributes.\n",
        "#y will determine if the tumor is benign or malign.\n",
        "#x will tell all the feautures on the column titles.\n",
        "x = dataset.drop(columns=[\"id\"]) # we're saying the \"x\" data is everying except in the column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6SR1kGrHrH0m"
      },
      "outputs": [],
      "source": [
        "y = dataset[\"id\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lecFCh2a9eUI"
      },
      "source": [
        "# II. Now we need to split the data into a training set and a testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TIReATdirsJu"
      },
      "outputs": [],
      "source": [
        "# This part is important because we see AI does well on data that it sees but falls apart when seeing new data.\n",
        "# To mitigate this, we'll seperate a part of our data aside to be tested on later.\n",
        "# What we're looking for is that the algoritm will be given a data that it has not seen before and see how it does.\n",
        "\n",
        "from sklearn.model_selection import train_test_split #We're importing it. The scikit-learn/sklearn is a free and open-source machine learning library for the Python.\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2) # 20% of our data will be in the testing set. It's normal to divide things up."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzEY1Qey9vMD"
      },
      "source": [
        "#III. Now let's build and train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1sZV8xFcscJb"
      },
      "outputs": [],
      "source": [
        "# To do this we'll be using TensorFlow Keras.\n",
        "#Keras is an open-source library that provides a Python interface for artificial neural networks.\n",
        "#Keras was first independent software, then integrated into the TensorFlow library, and later supporting more.\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "uVMgseK_spGy"
      },
      "outputs": [],
      "source": [
        "#We'll start adding layers to our module.\n",
        "#Refer to the neural network picture.\n",
        "#The Input layer is our x values with all attributes.\n",
        "\n",
        "model.add(tf.keras.layers.Dense(256, input_shape=x_train.shape[1:], activation='sigmoid'))\n",
        "#model.add(tf.keras.layers.Dense(256, input_shape=x_train.shape, activation='sigmoid')) #256 neurons is the power of 2 that we set.\n",
        "#we're saying we'll input something that the size of \"x_train\", which means all of the x feautures on the dataset.\n",
        "#The output will be 256 neurons.\n",
        "#Sigmoid function: we take all the values from neural network and plotting them between 0 and 1. It readuces the model's complexiy and makes it more accurate.\n",
        "\n",
        "model.add(tf.keras.layers.Dense(256, activation='sigmoid'))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) #This is the output layer.\n",
        "# 1 dense neuron because the final value will be  one single value between 1 and 0 on the diagnosis column.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "76olBreMtYA5"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#The optimizer we'll be using is called \"adam\".\n",
        "#This \"binary_crossentropy\" function is useful when using \"yes\" (1) or \"no\" (0) sort of results.\n",
        "#We want to classify as many chemical pollutants as possible so we use \"accuracy\" metrics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6L0D5R-7Q23"
      },
      "source": [
        "# V. Fit our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NDSwKNN0tpZQ",
        "outputId": "00af951b-8590-42ed-afad-10bfff5d4886"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/11\n",
            "\u001b[1m853/853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4961 - loss: nan\n",
            "Epoch 2/11\n",
            "\u001b[1m853/853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.4981 - loss: nan\n",
            "Epoch 3/11\n",
            "\u001b[1m853/853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4963 - loss: nan\n",
            "Epoch 4/11\n",
            "\u001b[1m853/853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4937 - loss: nan\n",
            "Epoch 5/11\n",
            "\u001b[1m853/853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5053 - loss: nan\n",
            "Epoch 6/11\n",
            "\u001b[1m853/853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5084 - loss: nan\n",
            "Epoch 7/11\n",
            "\u001b[1m853/853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5010 - loss: nan\n",
            "Epoch 8/11\n",
            "\u001b[1m853/853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5061 - loss: nan\n",
            "Epoch 9/11\n",
            "\u001b[1m853/853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4948 - loss: nan\n",
            "Epoch 10/11\n",
            "\u001b[1m853/853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4976 - loss: nan\n",
            "Epoch 11/11\n",
            "\u001b[1m853/853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4949 - loss: nan\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b27914d33a0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=11)\n",
        "#epochs means \"how many times the algoritm iterates over the same data\".\n",
        "#Algoritm learns going over and over on the same data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arBf4SAI9y0U"
      },
      "source": [
        "Evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Z3tEgrext4lQ",
        "outputId": "f2a1cf72-46c4-421f-b16f-7bf241f1a8fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5096 - loss: nan\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[nan, 0.5079155564308167]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPaI71f0uYfh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}